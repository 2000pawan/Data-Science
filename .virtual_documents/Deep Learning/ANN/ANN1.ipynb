### ANN


import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import warnings
warnings.filterwarnings('ignore')


df=pd.read_csv('/content/drive/MyDrive/DataSet/dataset/classification/iris1.csv')
df.drop(columns='id',inplace=True)
X=df.iloc[:,:-1].values
y=df.iloc[:,-1].values
model=Sequential()
model.add(Dense(3,activation='softmax'))
model.compile(optimizer='sgd',metrics=['accuracy'],loss='sparse_categorical_crossentropy')
model.fit(X,y,epochs=2000,batch_size=10,verbose=0)
print(model.history.history['loss'][-1])
print(model.history.history['accuracy'][-1])
sns.lineplot(x=range(1,2001),y=model.history.history['loss'],label='loss')
sns.lineplot(x=range(1,2001),y=model.history.history['accuracy'],label='accuracy')
plt.show()



sample=[[4.5,1.5,4.9,0.7]]
print(model.predict(sample))
print(np.argmax(model.predict(sample)) )


from collections import Counter
sample=X[40:110]
result=model.predict(sample)
max_index=np.argmax(result,axis=1)
print(Counter(max_index))
max_index
print(Counter(y[40:110]))
y[40:110]


### Multi-Layer Perceptron


df=pd.read_csv('/content/drive/MyDrive/DataSet/dataset/classification/iris1.csv')
df.drop(columns='id',inplace=True)
X=df.iloc[:,:-1].values
y=df.iloc[:,-1].values
model=Sequential()
model.add(Dense(50,activation='relu'))
model.add(Dense(3,activation='softmax'))
model.compile(optimizer='sgd',metrics=['accuracy'],loss='sparse_categorical_crossentropy')
model.fit(X,y,epochs=50,batch_size=32)


### DNN


df=pd.read_csv('/content/drive/MyDrive/DataSet/dataset/classification/iris1.csv')
df.drop(columns='id',inplace=True)
X=df.iloc[:,:-1].values
y=df.iloc[:,-1].values
model=Sequential()
model.add(Dense(20,activation='relu'))
model.add(Dense(50,activation='relu'))
model.add(Dense(20,activation='relu'))
model.add(Dense(3,activation='softmax'))
model.compile(optimizer='sgd',metrics=['accuracy'],loss='sparse_categorical_crossentropy')
model.fit(X,y,epochs=30,batch_size=32)


### Multi-layer Perceptron


df=pd.read_csv('/content/drive/MyDrive/DataSet/dataset/classification/iris1.csv')
df.drop(columns='id',inplace=True)
X=df.iloc[:,:-1].values
y=df.iloc[:,-1].values
model=Sequential()
model.add(Dense(50,activation='tanh'))
model.add(Dense(3,activation='softmax'))
model.compile(optimizer='sgd',metrics=['accuracy'],loss='sparse_categorical_crossentropy')
model.fit(X,y,epochs=50,batch_size=32)


df=pd.read_csv('/content/drive/MyDrive/DataSet/dataset/classification/iris1.csv')
df.drop(columns='id',inplace=True)
X=df.iloc[:,:-1].values
y=df.iloc[:,-1].values
model=Sequential()
model.add(Dense(50,activation='sigmoid'))
model.add(Dense(3,activation='softmax'))
model.compile(optimizer='sgd',metrics=['accuracy'],loss='sparse_categorical_crossentropy')
model.fit(X,y,epochs=50,batch_size=32)


## When we use softmax activation function in hidden layer performance of model is poor.
df=pd.read_csv('/content/drive/MyDrive/DataSet/dataset/classification/iris1.csv')
df.drop(columns='id',inplace=True)
X=df.iloc[:,:-1].values
y=df.iloc[:,-1].values
model=Sequential()
model.add(Dense(50,activation='softmax'))
model.add(Dense(3,activation='softmax'))
model.compile(optimizer='sgd',metrics=['accuracy'],loss='sparse_categorical_crossentropy')
model.fit(X,y,epochs=50,batch_size=32)


df=pd.read_csv('/content/drive/MyDrive/DataSet/dataset/classification/iris1.csv')
df.drop(columns='id',inplace=True)
X=df.iloc[:,:-1].values
y=df.iloc[:,-1].values
model=Sequential()
model.add(Dense(50,activation='leaky_relu'))
model.add(Dense(3,activation='softmax'))
model.compile(optimizer='sgd',metrics=['accuracy'],loss='sparse_categorical_crossentropy')
model.fit(X,y,epochs=50,batch_size=32)





from sklearn.model_selection import train_test_split


df=pd.read_csv('/content/drive/MyDrive/DataSet/dataset/classification/iris1.csv')
df.drop(columns='id',inplace=True)
X=df.iloc[:,:-1].values
y=df.iloc[:,-1].values
x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=10)
model=Sequential()
model.add(Dense(50,activation='relu'))
model.add(Dense(3,activation='softmax'))
model.compile(optimizer='sgd',metrics=['accuracy'],loss='sparse_categorical_crossentropy')
model.fit(x_train,y_train,epochs=500,batch_size=32)


model.evaluate(x_test,y_test)



